#!/usr/bin/env python# encoding: utf-8'''@author: 尹田农@license: (C) Copyright 2013-2017, Node Supply Chain Manager Corporation Limited.@contact: deamoncao100@gmail.com@software: garner@file: part1.py@time: 2018/12/17 20:28@desc:'''#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time    : 2018/12/17 16:48# @Author  : hbw# @Site    :# @File    : AI137_zhilian.py# @Software: PyCharmfrom lxml import etreeimport jsonimport urllib.request as req# 确定需求citys=['530', '538', '763', '765']kws=['python+web','爬虫','大数据','AI']# 标示爬虫采集的进度city_index=0kw_index=0start=0#固定套路while True:    # 动态模拟列表页请求    list_url='https://fe-api.zhaopin.com/c/i/sou?start='+str(start)+'&pageSize=90&cityId='+citys[city_index]+'&workExperience=-1&education=-1&companyType=-1&employmentType=-1&jobWelfareTag=-1&kw='+kws[kw_index]+'&kt=3&_v=0.03340125&x-zp-page-request-id=dcdb94bf31ee4563afee6c4e96f4ff67-1545036010607-163314'    # 解析列表页数据  获取总条数（总页数）和详情页连接    datas=json.loads(req.urlopen(list_url).read().decode('utf-8'))    num=int(datas['data']['numFound'])    # 遍历详情页列表    for data in datas['data']['results']:        # 发请求获取详情页对应的响应  timeout 请求超时时间  单位是秒        html,title,salary=''        try:            html = etree.HTML(req.urlopen(data['positionURL'],timeout=3).read())        except:            continue        print(data['positionURL'])        # 解析响应 返回html页面  可能有多套模板        try:            title=html.xpath('//h1/text()')[0]        except:            pass        salary=html.xpath('//div[@class="l info-money"]/strong/text()')[0]        company=html.xpath('//div[@class="company l"]/a/text()')[0]        zhize=''.join(html.xpath('//div[@class="pos-ul"]/p/text()'))        if not zhize:            zhize = ''.join(html.xpath('//div[@class="pos-ul"]/p/span/text()'))        print(title,salary,company,zhize)    # 自增页号    start+=90    # 断点记录    with open('log.log','w')as w:        w.write(str(city_index)+'\t')        w.write(str(kw_index)+'\t')        w.write(str(start))    # 改变参数，调整爬虫采集进度    if start>=num:        city_index+=1        start=0    if city_index>=len(citys):        kw_index+=1        city_index=0        start=0    # 当所有条件满足 结束采集    if kw_index>=len(kws):        break